# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2000-2017 Kitware, Inc. and Contributors
# This file is distributed under the same license as the CMake package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: CMake 3.8\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-03-04 18:22+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: ko_KR\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../../Modules/FindCUDA.cmake:3
msgid "FindCUDA"
msgstr ""

#: ../../../../Modules/FindCUDA.cmake:5
msgid "Tools for building CUDA C files: libraries and build dependencies."
msgstr ""

#: ../../../../Modules/FindCUDA.cmake:7
msgid ""
"This script locates the NVIDIA CUDA C tools.  It should work on linux, "
"windows, and mac and should be reasonably up to date with CUDA C releases."
msgstr ""

#: ../../../../Modules/FindCUDA.cmake:11
msgid ""
"This script makes use of the standard find_package arguments of <VERSION>, "
"REQUIRED and QUIET.  CUDA_FOUND will report if an acceptable version of CUDA "
"was found."
msgstr ""

#: ../../../../Modules/FindCUDA.cmake:15
msgid ""
"The script will prompt the user to specify CUDA_TOOLKIT_ROOT_DIR if the "
"prefix cannot be determined by the location of nvcc in the system path and "
"REQUIRED is specified to find_package().  To use a different installed "
"version of the toolkit set the environment variable CUDA_BIN_PATH before "
"running cmake (e.g. CUDA_BIN_PATH=/usr/local/cuda1.0 instead of the default /"
"usr/local/cuda) or set CUDA_TOOLKIT_ROOT_DIR after configuring.  If you "
"change the value of CUDA_TOOLKIT_ROOT_DIR, various components that depend on "
"the path will be relocated."
msgstr ""

#: ../../../../Modules/FindCUDA.cmake:25
msgid ""
"It might be necessary to set CUDA_TOOLKIT_ROOT_DIR manually on certain "
"platforms, or to use a cuda runtime not installed in the default location.  "
"In newer versions of the toolkit the cuda library is included with the "
"graphics driver- be sure that the driver version matches what is needed by "
"the cuda runtime version."
msgstr ""

#: ../../../../Modules/FindCUDA.cmake:31
msgid ""
"The following variables affect the behavior of the macros in the script (in "
"alphebetical order).  Note that any of these flags can be changed multiple "
"times in the same directory before calling CUDA_ADD_EXECUTABLE, "
"CUDA_ADD_LIBRARY, CUDA_COMPILE, CUDA_COMPILE_PTX, CUDA_COMPILE_FATBIN, "
"CUDA_COMPILE_CUBIN or CUDA_WRAP_SRCS::"
msgstr ""

#: ../../../../Modules/FindCUDA.cmake:37
msgid ""
"CUDA_64_BIT_DEVICE_CODE (Default matches host bit size)\n"
"-- Set to ON to compile for 64 bit device code, OFF for 32 bit device code.\n"
"   Note that making this different from the host code when generating "
"object\n"
"   or C files from CUDA code just won't work, because size_t gets defined "
"by\n"
"   nvcc in the generated source.  If you compile to PTX and then load the\n"
"   file yourself, you can mix bit sizes between device and host.\n"
"\n"
"CUDA_ATTACH_VS_BUILD_RULE_TO_CUDA_FILE (Default ON)\n"
"-- Set to ON if you want the custom build rule to be attached to the source\n"
"   file in Visual Studio.  Turn OFF if you add the same cuda file to "
"multiple\n"
"   targets.\n"
"\n"
"   This allows the user to build the target from the CUDA file; however, "
"bad\n"
"   things can happen if the CUDA source file is added to multiple targets.\n"
"   When performing parallel builds it is possible for the custom build\n"
"   command to be run more than once and in parallel causing cryptic build\n"
"   errors.  VS runs the rules for every source file in the target, and a\n"
"   source can have only one rule no matter how many projects it is added "
"to.\n"
"   When the rule is run from multiple targets race conditions can occur on\n"
"   the generated file.  Eventually everything will get built, but if the "
"user\n"
"   is unaware of this behavior, there may be confusion.  It would be nice "
"if\n"
"   this script could detect the reuse of source files across multiple "
"targets\n"
"   and turn the option off for the user, but no good solution could be "
"found.\n"
"\n"
"CUDA_BUILD_CUBIN (Default OFF)\n"
"-- Set to ON to enable and extra compilation pass with the -cubin option in\n"
"   Device mode. The output is parsed and register, shared memory usage is\n"
"   printed during build.\n"
"\n"
"CUDA_BUILD_EMULATION (Default OFF for device mode)\n"
"-- Set to ON for Emulation mode. -D_DEVICEEMU is defined for CUDA C files\n"
"   when CUDA_BUILD_EMULATION is TRUE.\n"
"\n"
"CUDA_GENERATED_OUTPUT_DIR (Default CMAKE_CURRENT_BINARY_DIR)\n"
"-- Set to the path you wish to have the generated files placed.  If it is\n"
"   blank output files will be placed in CMAKE_CURRENT_BINARY_DIR.\n"
"   Intermediate files will always be placed in\n"
"   CMAKE_CURRENT_BINARY_DIR/CMakeFiles.\n"
"\n"
"CUDA_HOST_COMPILATION_CPP (Default ON)\n"
"-- Set to OFF for C compilation of host code.\n"
"\n"
"CUDA_HOST_COMPILER (Default CMAKE_C_COMPILER, $(VCInstallDir)/bin for VS)\n"
"-- Set the host compiler to be used by nvcc.  Ignored if -ccbin or\n"
"   --compiler-bindir is already present in the CUDA_NVCC_FLAGS or\n"
"   CUDA_NVCC_FLAGS_<CONFIG> variables.  For Visual Studio targets\n"
"   $(VCInstallDir)/bin is a special value that expands out to the path when\n"
"   the command is run from within VS.\n"
"\n"
"CUDA_NVCC_FLAGS\n"
"CUDA_NVCC_FLAGS_<CONFIG>\n"
"-- Additional NVCC command line arguments.  NOTE: multiple arguments must "
"be\n"
"   semi-colon delimited (e.g. --compiler-options;-Wall)\n"
"\n"
"CUDA_PROPAGATE_HOST_FLAGS (Default ON)\n"
"-- Set to ON to propagate CMAKE_{C,CXX}_FLAGS and their configuration\n"
"   dependent counterparts (e.g. CMAKE_C_FLAGS_DEBUG) automatically to the\n"
"   host compiler through nvcc's -Xcompiler flag.  This helps make the\n"
"   generated host code match the rest of the system better.  Sometimes\n"
"   certain flags give nvcc problems, and this will help you turn the flag\n"
"   propagation off.  This does not affect the flags supplied directly to "
"nvcc\n"
"   via CUDA_NVCC_FLAGS or through the OPTION flags specified through\n"
"   CUDA_ADD_LIBRARY, CUDA_ADD_EXECUTABLE, or CUDA_WRAP_SRCS.  Flags used "
"for\n"
"   shared library compilation are not affected by this flag.\n"
"\n"
"CUDA_SEPARABLE_COMPILATION (Default OFF)\n"
"-- If set this will enable separable compilation for all CUDA runtime "
"object\n"
"   files.  If used outside of CUDA_ADD_EXECUTABLE and CUDA_ADD_LIBRARY\n"
"   (e.g. calling CUDA_WRAP_SRCS directly),\n"
"   CUDA_COMPUTE_SEPARABLE_COMPILATION_OBJECT_FILE_NAME and\n"
"   CUDA_LINK_SEPARABLE_COMPILATION_OBJECTS should be called.\n"
"\n"
"CUDA_SOURCE_PROPERTY_FORMAT\n"
"-- If this source file property is set, it can override the format "
"specified\n"
"   to CUDA_WRAP_SRCS (OBJ, PTX, CUBIN, or FATBIN).  If an input source file\n"
"   is not a .cu file, setting this file will cause it to be treated as a ."
"cu\n"
"   file. See documentation for set_source_files_properties on how to set\n"
"   this property.\n"
"\n"
"CUDA_USE_STATIC_CUDA_RUNTIME (Default ON)\n"
"-- When enabled the static version of the CUDA runtime library will be used\n"
"   in CUDA_LIBRARIES.  If the version of CUDA configured doesn't support\n"
"   this option, then it will be silently disabled.\n"
"\n"
"CUDA_VERBOSE_BUILD (Default OFF)\n"
"-- Set to ON to see all the commands used when building the CUDA file.  "
"When\n"
"   using a Makefile generator the value defaults to VERBOSE (run make\n"
"   VERBOSE=1 to see output), although setting CUDA_VERBOSE_BUILD to ON will\n"
"   always print the output."
msgstr ""

#: ../../../../Modules/FindCUDA.cmake:127
msgid "The script creates the following macros (in alphebetical order)::"
msgstr ""

#: ../../../../Modules/FindCUDA.cmake:129
msgid ""
"CUDA_ADD_CUFFT_TO_TARGET( cuda_target )\n"
"-- Adds the cufft library to the target (can be any target).  Handles "
"whether\n"
"   you are in emulation mode or not.\n"
"\n"
"CUDA_ADD_CUBLAS_TO_TARGET( cuda_target )\n"
"-- Adds the cublas library to the target (can be any target).  Handles\n"
"   whether you are in emulation mode or not.\n"
"\n"
"CUDA_ADD_EXECUTABLE( cuda_target file0 file1 ...\n"
"                     [WIN32] [MACOSX_BUNDLE] [EXCLUDE_FROM_ALL] "
"[OPTIONS ...] )\n"
"-- Creates an executable \"cuda_target\" which is made up of the files\n"
"   specified.  All of the non CUDA C files are compiled using the standard\n"
"   build rules specified by CMAKE and the cuda files are compiled to object\n"
"   files using nvcc and the host compiler.  In addition CUDA_INCLUDE_DIRS "
"is\n"
"   added automatically to include_directories().  Some standard CMake "
"target\n"
"   calls can be used on the target after calling this macro\n"
"   (e.g. set_target_properties and target_link_libraries), but setting\n"
"   properties that adjust compilation flags will not affect code compiled "
"by\n"
"   nvcc.  Such flags should be modified before calling CUDA_ADD_EXECUTABLE,\n"
"   CUDA_ADD_LIBRARY or CUDA_WRAP_SRCS.\n"
"\n"
"CUDA_ADD_LIBRARY( cuda_target file0 file1 ...\n"
"                  [STATIC | SHARED | MODULE] [EXCLUDE_FROM_ALL] "
"[OPTIONS ...] )\n"
"-- Same as CUDA_ADD_EXECUTABLE except that a library is created.\n"
"\n"
"CUDA_BUILD_CLEAN_TARGET()\n"
"-- Creates a convience target that deletes all the dependency files\n"
"   generated.  You should make clean after running this target to ensure "
"the\n"
"   dependency files get regenerated.\n"
"\n"
"CUDA_COMPILE( generated_files file0 file1 ... [STATIC | SHARED | MODULE]\n"
"              [OPTIONS ...] )\n"
"-- Returns a list of generated files from the input source files to be used\n"
"   with ADD_LIBRARY or ADD_EXECUTABLE.\n"
"\n"
"CUDA_COMPILE_PTX( generated_files file0 file1 ... [OPTIONS ...] )\n"
"-- Returns a list of PTX files generated from the input source files.\n"
"\n"
"CUDA_COMPILE_FATBIN( generated_files file0 file1 ... [OPTIONS ...] )\n"
"-- Returns a list of FATBIN files generated from the input source files.\n"
"\n"
"CUDA_COMPILE_CUBIN( generated_files file0 file1 ... [OPTIONS ...] )\n"
"-- Returns a list of CUBIN files generated from the input source files.\n"
"\n"
"CUDA_COMPUTE_SEPARABLE_COMPILATION_OBJECT_FILE_NAME( output_file_var\n"
"                                                     cuda_target\n"
"                                                     object_files )\n"
"-- Compute the name of the intermediate link file used for separable\n"
"   compilation.  This file name is typically passed into\n"
"   CUDA_LINK_SEPARABLE_COMPILATION_OBJECTS.  output_file_var is produced\n"
"   based on cuda_target the list of objects files that need separable\n"
"   compilation as specified by object_files.  If the object_files list is\n"
"   empty, then output_file_var will be empty.  This function is called\n"
"   automatically for CUDA_ADD_LIBRARY and CUDA_ADD_EXECUTABLE.  Note that\n"
"   this is a function and not a macro.\n"
"\n"
"CUDA_INCLUDE_DIRECTORIES( path0 path1 ... )\n"
"-- Sets the directories that should be passed to nvcc\n"
"   (e.g. nvcc -Ipath0 -Ipath1 ... ). These paths usually contain other .cu\n"
"   files.\n"
"\n"
"\n"
"CUDA_LINK_SEPARABLE_COMPILATION_OBJECTS( output_file_var cuda_target\n"
"                                         nvcc_flags object_files)\n"
"-- Generates the link object required by separable compilation from the "
"given\n"
"   object files.  This is called automatically for CUDA_ADD_EXECUTABLE and\n"
"   CUDA_ADD_LIBRARY, but can be called manually when using CUDA_WRAP_SRCS\n"
"   directly.  When called from CUDA_ADD_LIBRARY or CUDA_ADD_EXECUTABLE the\n"
"   nvcc_flags passed in are the same as the flags passed in via the OPTIONS\n"
"   argument.  The only nvcc flag added automatically is the bitness flag as\n"
"   specified by CUDA_64_BIT_DEVICE_CODE.  Note that this is a function\n"
"   instead of a macro.\n"
"\n"
"CUDA_SELECT_NVCC_ARCH_FLAGS(out_variable [target_CUDA_architectures])\n"
"-- Selects GPU arch flags for nvcc based on target_CUDA_architectures\n"
"   target_CUDA_architectures : Auto | Common | All | LIST(ARCH_AND_PTX ...)\n"
"    - \"Auto\" detects local machine GPU compute arch at runtime.\n"
"    - \"Common\" and \"All\" cover common and entire subsets of "
"architectures\n"
"   ARCH_AND_PTX : NAME | NUM.NUM | NUM.NUM(NUM.NUM) | NUM.NUM+PTX\n"
"   NAME: Fermi Kepler Maxwell Kepler+Tegra Kepler+Tesla Maxwell+Tegra "
"Pascal\n"
"   NUM: Any number. Only those pairs are currently accepted by NVCC though:\n"
"         2.0 2.1 3.0 3.2 3.5 3.7 5.0 5.2 5.3 6.0 6.2\n"
"   Returns LIST of flags to be added to CUDA_NVCC_FLAGS in ${out_variable}\n"
"   Additionally, sets ${out_variable}_readable to the resulting numeric "
"list\n"
"   Example:\n"
"    CUDA_SELECT_NVCC_ARCH_FLAGS(ARCH_FLAGS 3.0 3.5+PTX 5.2(5.0) Maxwell)\n"
"     LIST(APPEND CUDA_NVCC_FLAGS ${ARCH_FLAGS})\n"
"\n"
"   More info on CUDA architectures: https://en.wikipedia.org/wiki/CUDA\n"
"   Note that this is a function instead of a macro.\n"
"\n"
"CUDA_WRAP_SRCS ( cuda_target format generated_files file0 file1 ...\n"
"                 [STATIC | SHARED | MODULE] [OPTIONS ...] )\n"
"-- This is where all the magic happens.  CUDA_ADD_EXECUTABLE,\n"
"   CUDA_ADD_LIBRARY, CUDA_COMPILE, and CUDA_COMPILE_PTX all call this\n"
"   function under the hood.\n"
"\n"
"   Given the list of files (file0 file1 ... fileN) this macro generates\n"
"   custom commands that generate either PTX or linkable objects (use \"PTX\" "
"or\n"
"   \"OBJ\" for the format argument to switch).  Files that don't end with ."
"cu\n"
"   or have the HEADER_FILE_ONLY property are ignored.\n"
"\n"
"   The arguments passed in after OPTIONS are extra command line options to\n"
"   give to nvcc.  You can also specify per configuration options by\n"
"   specifying the name of the configuration followed by the options.  "
"General\n"
"   options must precede configuration specific options.  Not all\n"
"   configurations need to be specified, only the ones provided will be "
"used.\n"
"\n"
"      OPTIONS -DFLAG=2 \"-DFLAG_OTHER=space in flag\"\n"
"      DEBUG -g\n"
"      RELEASE --use_fast_math\n"
"      RELWITHDEBINFO --use_fast_math;-g\n"
"      MINSIZEREL --use_fast_math\n"
"\n"
"   For certain configurations (namely VS generating object files with\n"
"   CUDA_ATTACH_VS_BUILD_RULE_TO_CUDA_FILE set to ON), no generated file "
"will\n"
"   be produced for the given cuda file.  This is because when you add the\n"
"   cuda file to Visual Studio it knows that this file produces an object "
"file\n"
"   and will link in the resulting object file automatically.\n"
"\n"
"   This script will also generate a separate cmake script that is used at\n"
"   build time to invoke nvcc.  This is for several reasons.\n"
"\n"
"     1. nvcc can return negative numbers as return values which confuses\n"
"     Visual Studio into thinking that the command succeeded.  The script "
"now\n"
"     checks the error codes and produces errors when there was a problem.\n"
"\n"
"     2. nvcc has been known to not delete incomplete results when it\n"
"     encounters problems.  This confuses build systems into thinking the\n"
"     target was generated when in fact an unusable file exists.  The script\n"
"     now deletes the output files if there was an error.\n"
"\n"
"     3. By putting all the options that affect the build into a file and "
"then\n"
"     make the build rule dependent on the file, the output files will be\n"
"     regenerated when the options change.\n"
"\n"
"   This script also looks at optional arguments STATIC, SHARED, or MODULE "
"to\n"
"   determine when to target the object compilation for a shared library.\n"
"   BUILD_SHARED_LIBS is ignored in CUDA_WRAP_SRCS, but it is respected in\n"
"   CUDA_ADD_LIBRARY.  On some systems special flags are added for building\n"
"   objects intended for shared libraries.  A preprocessor macro,\n"
"   <target_name>_EXPORTS is defined when a shared library compilation is\n"
"   detected.\n"
"\n"
"   Flags passed into add_definitions with -D or /D are passed along to nvcc."
msgstr ""

#: ../../../../Modules/FindCUDA.cmake:277
msgid "The script defines the following variables::"
msgstr ""

#: ../../../../Modules/FindCUDA.cmake:279
msgid ""
"CUDA_VERSION_MAJOR    -- The major version of cuda as reported by nvcc.\n"
"CUDA_VERSION_MINOR    -- The minor version.\n"
"CUDA_VERSION\n"
"CUDA_VERSION_STRING   -- CUDA_VERSION_MAJOR.CUDA_VERSION_MINOR\n"
"CUDA_HAS_FP16         -- Whether a short float (float16,fp16) is supported.\n"
"\n"
"CUDA_TOOLKIT_ROOT_DIR -- Path to the CUDA Toolkit (defined if not set).\n"
"CUDA_SDK_ROOT_DIR     -- Path to the CUDA SDK.  Use this to find files in "
"the\n"
"                         SDK.  This script will not directly support "
"finding\n"
"                         specific libraries or headers, as that isn't\n"
"                         supported by NVIDIA.  If you want to change\n"
"                         libraries when the path changes see the\n"
"                         FindCUDA.cmake script for an example of how to "
"clear\n"
"                         these variables.  There are also examples of how "
"to\n"
"                         use the CUDA_SDK_ROOT_DIR to locate headers or\n"
"                         libraries, if you so choose (at your own risk).\n"
"CUDA_INCLUDE_DIRS     -- Include directory for cuda headers.  Added "
"automatically\n"
"                         for CUDA_ADD_EXECUTABLE and CUDA_ADD_LIBRARY.\n"
"CUDA_LIBRARIES        -- Cuda RT library.\n"
"CUDA_CUFFT_LIBRARIES  -- Device or emulation library for the Cuda FFT\n"
"                         implementation (alternative to:\n"
"                         CUDA_ADD_CUFFT_TO_TARGET macro)\n"
"CUDA_CUBLAS_LIBRARIES -- Device or emulation library for the Cuda BLAS\n"
"                         implementation (alternative to:\n"
"                         CUDA_ADD_CUBLAS_TO_TARGET macro).\n"
"CUDA_cudart_static_LIBRARY -- Statically linkable cuda runtime library.\n"
"                              Only available for CUDA version 5.5+\n"
"CUDA_cudadevrt_LIBRARY -- Device runtime library.\n"
"                          Required for separable compilation.\n"
"CUDA_cupti_LIBRARY    -- CUDA Profiling Tools Interface library.\n"
"                         Only available for CUDA version 4.0+.\n"
"CUDA_curand_LIBRARY   -- CUDA Random Number Generation library.\n"
"                         Only available for CUDA version 3.2+.\n"
"CUDA_cusolver_LIBRARY -- CUDA Direct Solver library.\n"
"                         Only available for CUDA version 7.0+.\n"
"CUDA_cusparse_LIBRARY -- CUDA Sparse Matrix library.\n"
"                         Only available for CUDA version 3.2+.\n"
"CUDA_npp_LIBRARY      -- NVIDIA Performance Primitives lib.\n"
"                         Only available for CUDA version 4.0+.\n"
"CUDA_nppc_LIBRARY     -- NVIDIA Performance Primitives lib (core).\n"
"                         Only available for CUDA version 5.5+.\n"
"CUDA_nppi_LIBRARY     -- NVIDIA Performance Primitives lib (image "
"processing).\n"
"                         Only available for CUDA version 5.5+.\n"
"CUDA_npps_LIBRARY     -- NVIDIA Performance Primitives lib (signal "
"processing).\n"
"                         Only available for CUDA version 5.5+.\n"
"CUDA_nvcuvenc_LIBRARY -- CUDA Video Encoder library.\n"
"                         Only available for CUDA version 3.2+.\n"
"                         Windows only.\n"
"CUDA_nvcuvid_LIBRARY  -- CUDA Video Decoder library.\n"
"                         Only available for CUDA version 3.2+.\n"
"                         Windows only."
msgstr ""
